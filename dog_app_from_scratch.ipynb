{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import cv2   \n",
    "import time\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt                        \n",
    "from tqdm import tqdm                       \n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import socket\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import math\n",
    "ceil = math.ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n",
      "0.2.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import torchvision\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available as: True\n"
     ]
    }
   ],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    print('GPU is available as:',CUDA)\n",
    "else:\n",
    "    print('GPU is available as:',CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8351 total dog images.\n"
     ]
    }
   ],
   "source": [
    "# Load dog files\n",
    "if socket.gethostname() == 'zT5610':\n",
    "    dog_files = np.array(glob(\"dogImages/*/*/*\"))\n",
    "else:\n",
    "    dog_files = np.array(glob(\"/data/dog_images/*/*/*\"))\n",
    "\n",
    "# print number of images in each dataset\n",
    "print('There are %d total dog images.' % len(dog_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n"
     ]
    }
   ],
   "source": [
    "dog_classes = []\n",
    "for i in range(dog_files.shape[0]):\n",
    "    s = dog_files[i-1]\n",
    "    s = s[0:s.rfind('.jpg')]\n",
    "    s = s[0:s.rfind(\"_\")]\n",
    "    s = s[0:s.rfind(\"/\")]\n",
    "    s = s[1+s.find(\".\"):len(s)]\n",
    "    dog_classes.append(s)\n",
    "dog_classes = list(set(dog_classes))\n",
    "print(len(dog_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 30\n",
    "num_workers = 0\n",
    "num_classes = len(dog_classes)\n",
    "input_size = 224       #Number of input neurons (image pixels)\n",
    "num_epochs = 10        #Number of epochs\n",
    "learning_rate = 0.01  #How fast the model learns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([transforms.Resize(224),\n",
    "                                     transforms.RandomResizedCrop(224),\n",
    "                                     transforms.ToTensor()\n",
    "                                    ])\n",
    "\n",
    "### TODO: Write data loaders for training, validation, and test sets\n",
    "## Specify appropriate transforms, and batch_sizes\n",
    "if socket.gethostname() == 'zT5610': # In my local environment\n",
    "    train_dir, validation_dir, test_dir = \"dogImages/train/\", \"dogImages/valid/\", \"dogImages/test/\"\n",
    "else: # In Udacity environment\n",
    "    train_dir, validation_dir, test_dir = \"/data/dog_images/train/\", \"/data/dog_images/valid/\", \"/data/dog_images/test/\"\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=data_transform)\n",
    "validation_data = datasets.ImageFolder(validation_dir, transform=data_transform)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, \n",
    "                                           batch_size=batch_size,\n",
    "                                           num_workers=num_workers, \n",
    "                                           shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data, \n",
    "                                                batch_size=batch_size,\n",
    "                                                num_workers=num_workers, \n",
    "                                                shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=batch_size, \n",
    "                                          num_workers=num_workers, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Points:\t\t 6680\n",
      "Validation Data Points:\t\t 835\n",
      "Test Data Points:\t\t 836\n",
      "Number of Classes:\t\t 133\n"
     ]
    }
   ],
   "source": [
    "print('Train Data Points:\\t\\t',str(len(train_data.imgs)))\n",
    "print('Validation Data Points:\\t\\t',str(len(validation_data.imgs)))\n",
    "print('Test Data Points:\\t\\t',str(len(test_data.imgs)))\n",
    "print('Number of Classes:\\t\\t',str(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, bias=True)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, bias=True)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, bias=True)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, bias=True)\n",
    "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, bias=True)\n",
    "        self.fc1 = nn.Linear(in_features=256 * 6 * 6, out_features=133, bias=True)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2,ceil_mode=True)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.conv_bn1 = nn.BatchNorm2d(num_features=224,eps=1e-05)\n",
    "        self.conv_bn2 = nn.BatchNorm2d(num_features=16)\n",
    "        self.conv_bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        self.conv_bn4 = nn.BatchNorm2d(num_features=64)\n",
    "        self.conv_bn5 = nn.BatchNorm2d(num_features=128)\n",
    "        self.conv_bn6 = nn.BatchNorm2d(num_features=256)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.softmax(self.conv1(x))\n",
    "        x = self.max_pool(x)\n",
    "        x = self.conv_bn2(x)\n",
    "        \n",
    "        x = F.softmax(self.conv2(x))\n",
    "        x = self.max_pool(x)\n",
    "        x = self.conv_bn3(x)\n",
    "        \n",
    "        x = F.softmax(self.conv3(x))\n",
    "        x = self.max_pool(x)\n",
    "        x = self.conv_bn4(x)\n",
    "        \n",
    "        x = F.softmax(self.conv4(x))\n",
    "        x = self.max_pool(x)\n",
    "        x = self.conv_bn5(x)\n",
    "        \n",
    "        x = F.softmax(self.conv5(x))\n",
    "        x = self.max_pool(x)\n",
    "        x = self.conv_bn6(x)\n",
    "        \n",
    "        x = x.view(-1, 256 * 6 * 6)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()       \n",
    "        # Hyperparameters\n",
    "        c1_in,c1_out,c1_k,c1_s,c1_p = train_data[0][0].size()[0],16,5,1,2\n",
    "        p1_k = 2\n",
    "        \n",
    "        c2_in,c2_out,c2_k,c2_s,c2_p = c1_out,c1_out*2,5,1,2\n",
    "        p2_k = 2\n",
    "        \n",
    "        w,h = train_data[0][0].size()[1],train_data[0][0].size()[2]\n",
    "        \n",
    "        o1 = ceil((w-c1_k+2*c1_p)/c1_s+1)\n",
    "        m1 = ceil(o1/p1_k)\n",
    "        o2 = ceil((m1-c2_k+2*c2_p)/c2_s+1)\n",
    "        m2 = ceil(o2/p2_k)\n",
    "        \n",
    "        f1_in,f1_out = c2_out*m2*m2,ceil(c2_out*m2*m2/28)\n",
    "        \n",
    "        f2_in,f2_out = f1_out,num_classes\n",
    "        \n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=c1_in,out_channels=c1_out,kernel_size=c1_k,stride=c1_s,padding=c1_p)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Max pool 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=p1_k)\n",
    "     \n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=c2_in, out_channels=c2_out, kernel_size=c2_k, stride=c2_s, padding=c2_p)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Max pool 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=p2_k)\n",
    "        \n",
    "        # Fully connected 1\n",
    "        self.fc1 = nn.Linear(in_features=f1_in, out_features=f1_out) \n",
    "        \n",
    "        # Fully connected 2\n",
    "        self.fc2 = nn.Linear(in_features=f2_in, out_features=f2_out) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        # Max pool 1\n",
    "        out = self.maxpool1(out)\n",
    "        \n",
    "        # Convolution 2 \n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        # Max pool 2 \n",
    "        out = self.maxpool2(out)\n",
    "        \n",
    "        # Flatten 32*56*56\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net2(\n",
      "  (cnn1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=100352, out_features=3584, bias=True)\n",
      "  (fc2): Linear(in_features=3584, out_features=133, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiate the CNN\n",
    "model_scratch = Net2()\n",
    "print(model_scratch)\n",
    "# move tensors to GPU if CUDA is available\n",
    "if CUDA:\n",
    "    model_scratch.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs,loaders,model,optimizer,criterion,use_cuda,save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        #scheduler.step()\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            ## record the average training loss, using something like\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(validation_loader):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## update the average validation loss\n",
    "             # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update average validation loss \n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "\n",
    "# calculate average losses\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        valid_loss = valid_loss/len(validation_loader.dataset)\n",
    "\n",
    "# print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        \n",
    "        ## save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss    \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: select loss function\n",
    "criterion_scratch = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "optimizer_scratch = optim.SGD(model_scratch.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "# monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        # move to GPU\n",
    "        if CUDA:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (100. * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results:\n",
      "Epoch: 1 \tTraining Loss: 0.000730 \tValidation Loss: 0.005819\n",
      "Validation loss decreased (inf --> 0.005819).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000727 \tValidation Loss: 0.005797\n",
      "Validation loss decreased (0.005819 --> 0.005797).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.000722 \tValidation Loss: 0.005742\n",
      "Validation loss decreased (0.005797 --> 0.005742).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000713 \tValidation Loss: 0.005662\n",
      "Validation loss decreased (0.005742 --> 0.005662).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.000701 \tValidation Loss: 0.005662\n",
      "\n",
      "Test Results:\n",
      "Test Loss: 4.746204\n",
      "\n",
      "\n",
      "Test Accuracy:  2% (18/836)\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "print('Train Results:')\n",
    "model_scratch = train(n_epochs=5, \n",
    "                      loaders=train_loader, # good\n",
    "                      model=model_scratch, # good\n",
    "                      optimizer=optimizer_scratch, # good\n",
    "                      criterion=criterion_scratch, # good \n",
    "                      use_cuda=CUDA, # good\n",
    "                      save_path='model_scratch.pt' # good\n",
    "                     )\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model_scratch.load_state_dict(torch.load('model_scratch.pt'))\n",
    "\n",
    "print('\\nTest Results:')\n",
    "test(test_loader, model_scratch, criterion_scratch, CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_PyTorch",
   "language": "python",
   "name": "pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
